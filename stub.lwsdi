val %( + ) : Int -> Int -> Int
  external (builtin = "int_add", surface = "+")
val %( - ) : Int -> Int -> Int
  external (builtin = "int_sub", surface = "-")
val %( * ) : Int -> Int -> Int
  external (builtin = "int_mult", surface = "*")
val %( // ) : Int -> Int -> Int
  external (builtin = "int_div", surface = "//")
val %( / ) : Float -> Float -> Float
  external (builtin = "float_div", surface = "/")
val %( <= ) : Int -> Int -> Bool
  external (builtin = "int_leq", surface = "<=")
val ~gen_vadd : {a : Nat} -> &(Vec %a -> Vec %a -> Vec %a)
  external (builtin = "gen_vadd", surface = "vadd")
val ~gen_vconcat : {a : Nat} -> {b : Nat} -> &(Vec %a -> Vec %b -> Vec %(a + b))
  external (builtin = "gen_vconcat", surface = "vconcat")
val ~gen_mtranspose : {a : Nat} -> {b : Nat} -> &(Mat %a %b -> Mat %b %a)
  external (builtin = "gen_mtranspose", surface = "mtranspose")
val ~gen_mmult : {a : Nat} -> {b : Nat} -> {c : Nat} -> &(Mat %a %b -> Mat %b %c -> Mat %a %c)
  external (builtin = "tensor__gen_mm", surface = "mmult")
    (* TODO: replace this with `Tensor.gen_mm` *)
val ~gen_mconcat_vert : {a : Nat} -> {b : Nat} -> {c : Nat} -> &(Mat %a %c -> Mat %b %c -> Mat %(a + b) %c)
  external (builtin = "gen_mconcat_vert", surface = "mconcat_vert")
val ~drop_at : Nat -> List Nat -> List Nat
  external (builtin = "drop_at", surface = "drop_at")
val ~broadcastable : List Nat -> List Nat -> Bool
  external (builtin = "broadcastable", surface = "broadcastable")
val ~broadcast : List Nat -> List Nat -> List Nat
  external (builtin = "broadcast", surface = "broadcast")
(* TODO: make `reshapeable` support `-1` *)
val ~reshapeable : List Nat -> List Nat -> Bool
  external (builtin = "reshapeable", surface = "reshapeable")
val %float : Int -> Float
  external (builtin = "float", surface = "float")
val print_float : Float -> Unit
  external (builtin = "print_float", surface = "print_float")
val %range : Int -> Int -> List Int
  external (builtin = "range", surface = "range")

module List = struct
  val %append : List Int -> List Int -> List Int
(*  val %append 'a : List 'a -> List 'a -> List 'a  *)
    external (builtin = "list__append", surface = "append") (* TODO: generalize the type *)
  val %iter : (Int -> Unit) -> List Int -> Unit
    external (builtin = "list__iter", surface = "iter") (* TODO: generalize the type *)
end

module Device = struct
  val ~cuda_if_available : Unit -> Unit (* TODO: introduce `Device` *)
    external (builtin = "device__cuda_if_available", surface = "cuda_if_available")
end

module Tensor = struct
  val ~gen_zeros : (shape : List Nat) -> &(Tensor %shape)
    external (builtin = "tensor__gen_zeros", surface = "zeros")
  val ~gen_add :
    {shape1 : List Nat} -> {shape2 : (s : List Nat | broadcastable shape1 s)} ->
    &(Tensor %shape1 -> Tensor %shape2 -> Tensor %(broadcast shape1 shape2))
    external (builtin = "tensor__gen_add", surface = "+")
  val ~gen_mult :
    {shape1 : List Nat} -> {shape2 : (s : List Nat | broadcastable shape1 s)} ->
    &(Tensor %shape1 -> Tensor %shape2 -> Tensor %(broadcast shape1 shape2))
    external (builtin = "tensor__gen_mult", surface = "*")
  val ~gen_grad : {shape : List Nat} -> &(Tensor %shape -> Tensor %shape)
    external (builtin = "tensor__gen_grad", surface = "grad")
  val ~gen_zero_grad : {shape : List Nat} -> &(Tensor %shape -> Unit)
    external (builtin = "tensor__gen_zero_grad", surface = "zero_grad")
  val ~gen_mm : {a : Nat} -> {b : Nat} -> {c : Nat} -> &(Mat %a %b -> Mat %b %c -> Mat %a %c)
    external (builtin = "tensor__gen_mm", surface = "mm")
  val ~gen_sub_update : {shape : List Nat} -> &(Tensor %shape -> Tensor %shape -> Unit)
    external (builtin = "tensor__gen_sub_update", surface = "-=")
  val ~gen_argmax : {shape : List Nat} -> (dim : Nat) -> &(Tensor %shape -> Tensor %(drop_at dim shape))
    external (builtin = "tensor__gen_argmax", surface = "argmax")
  val ~gen_cross_entropy_for_logits :
    {m : Nat} -> {n : Nat} ->
    &(Tensor %[m, n] -> Tensor %[m] -> Tensor %[])
    external (builtin = "tensor__gen_cross_entropy_for_logits", surface = "cross_entropy_for_logits")
  val ~gen_count_equal : {shape : List Nat} -> &(Tensor %shape -> Tensor %shape -> Int)
    external (builtin = "tensor__gen_count_equal", surface = "count_equal")
  val f : Float -> Tensor %[]
    external (builtin = "tensor__f", surface = "f")
  val backward : Tensor %[] -> Unit
    external (builtin = "tensor__backward", surface = "backward")
  val no_grad : (Unit -> Unit) -> Unit
    external (builtin = "tensor__no_grad", surface = "no_grad")
  val float_value : Tensor %[] -> Float
    external (builtin = "tensor__float_value", surface = "float_value")
  val ~gen_dropout :
    {shape : List Nat} ->
    &(Float -> (* dropout prob *)
      Bool -> (* is_training *)
      Tensor %shape ->
      Tensor %shape
    )
    external (builtin = "tensor__gen_dropout", surface = "dropout")
  (* TODO: make `gen_reshape` support `-1` *)
  val ~gen_reshape :
    {shape1 : List Nat} ->
    (shape2 : ( sh : List Nat | reshapeable shape1 sh )) ->
    &(Tensor %shape1 ->
      Tensor %shape2
    )
    external (builtin = "tensor__gen_reshape", surface = "reshape")
  val ~gen_max_pool2d :
    {k : Nat} ->
    {l : Nat} ->
    {m : Nat} ->
    {n : Nat} ->
    (padding1 : Int) ->
    (padding2 : Int) ->
    (ksize1 : Int) ->
    (ksize2 : Int) ->
    (stride1 : Int) ->
    (stride2 : Int) ->
    &(Tensor %[k, l, m, n] ->
      Tensor %[k, l, (m + 2 * padding1 - ksize1) // stride1 + 1, (n + 2 * padding2 - ksize2) // stride2 + 1]
    )
    external (builtin = "tensor__gen_max_pool2d", surface = "max_pool2d")
end

module Layer = struct
  val ~gen_forward :
    {shape1 : List Nat} ->
    {shape2 : List Nat} ->
    &((Tensor %shape1 -> Tensor %shape2) ->
      Tensor %shape1 -> Tensor %shape2
    )
    external (builtin = "layer__gen_forward", surface = "forward")
  val ~gen_conv2d_ :
    {l : Nat} ->
    {m : Nat} ->
    {n : Nat} ->
    Unit -> (* TODO: replace this type with `VarStore` *)
    (ksize : Int) ->
    (stride : Int) ->
    (padding : Int) ->
    (input_dim : Nat) ->
    (output_dim : Nat) ->
    &(Tensor %[l, input_dim, m, n] ->
      Tensor %[l, output_dim, (m + 2 * padding - ksize) // stride + 1, (n + 2 * padding - ksize) // stride + 1]
    )
    external (builtin = "layer__gen_conv2d_", surface = "conv2d_")
  val ~gen_linear :
    {ns : List Nat} ->
    Unit -> (* TODO: replace this type with `VarStore` *)
    Unit -> (* TODO: replace this type with `Activation` *)
    (input_dim : Nat) ->
    (output_dim : Nat) ->
    &(Tensor %(List.append ns [input_dim]) ->
      Tensor %(List.append ns [output_dim])
    )
    external (builtin = "layer__gen_linear", surface = "linear")
end

module Var_store = struct
  val create : String -> Unit ->
    Unit (* TODO: replace the return type with `VarStore` *)
    external (builtin = "var_store__create", surface = "create")
end

module Optimizer = struct
  val adam :
    Unit -> (* TODO: replace this type with `VarStore` *)
    Float ->
    Unit (* TODO: replace the return type with `Optimizer` *)
    external (builtin = "optimizer__adam", surface = "adam")
end

module Dataset_helper = struct
  val ~gen_train_batch :
    {ntrain : Nat} ->
    {ntest : Nat} ->
    {imgdim : Nat} ->
    (batch_size : Nat) ->
    &(Tensor %[ntrain, imgdim] ->
      Tensor %[ntrain] ->
      Tensor %[ntest, imgdim] ->
      Tensor %[ntest] ->
      Int ->
      Tensor %[batch_size, imgdim] * Tensor %[batch_size]
    )
    external (builtin = "dataset_helper__gen_train_batch", surface = "train_batch")
end

module Mnist_helper = struct
  val ~image_dim = (28 * 28) as Nat
  val ~label_count = 10
  val train_images : Tensor %[60000, image_dim]
    external (builtin = "mnist_helper__train_images", surface = "train_images")
  val train_labels : Tensor %[60000]
    external (builtin = "mnist_helper__train_labels", surface = "train_labels")
  val num_test_images = 10000
  val test_images : Tensor %[10000, image_dim]
    external (builtin = "mnist_helper__test_images", surface = "test_images")
  val test_labels : Tensor %[10000]
    external (builtin = "mnist_helper__test_labels", surface = "test_labels")
end
